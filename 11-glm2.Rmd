

```{r, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(nnet)
library(MASS)
library(ordinal)
library(pscl)
library(knitr)
```

# 一般化線形モデルの応用

前の章では、代表的な一般化線形モデルとして、ロジスティック回帰とポアソン回帰を学んだ。この章では、一般化線形モデルを応用したその他の解析法について説明する。  
  
* 負の二項回帰（過分散対策）  
* 順序ロジスティック回帰  
* 多項ロジスティック回帰   

## 準備

可視化のための`ggplot2`パッケージに加え、`MASS`、`ordinal`、`nnet`パッケージを使う。  
`MASS`パッケージは負の二項分布を用いたモデルのときに、`ordinal`パッケージは順序ロジスティック回帰のときに、`nnet`パッケージは多項ロジスティック回帰のときに必要になる。初めて使う際には、事前にインストールが必要なので注意。


```{r, eval=FALSE}

library(ggplot2)
library(MASS)
library(ordinal)
library(nnet)

```



## 負の二項回帰

前の章で、応答変数がカウントデータの場合、ポアソン回帰で解析するのが適切であると学んだ。しかし、実際のデータは分散が平均よりも大きい場合が多く、平均と分散が等しいという前提のポアソン分布を用いると予測変数の効果を誤って判断してしまう恐れがある。これが、**過分散（overdispersion）**と呼ばれる問題である。  
  
過分散対策として、応答変数が従う分布としてポアソン分布の代わりに、**負の二項分布(negative binomial distribution)**を用いる方法がよく使われる。  
  
### 負の二項分布

例えばコインを投げて表が出る確率を0.5として、表が3回出るまで投げると決めたとする。8回投げたところで表が3回出た場合、表が3回出る確率は以下から求めることができる。


```{r}

choose(8-1, 3-1) * 0.5^2 * (1-0.5)^(8-3) * 0.5 #つまり、7回中表が2回、裏が5回出て、最後の１回で表が出る確率を求める。

```


これを一般化した式が以下である。成功確率を$q$、成功回数を$r$、全試行数（成功回数+失敗回数）を$n$とした場合の確率$P(n)$を表している。（上の例の場合は、$q=0.5$, $r=3$, $n=8$である）

$$
P(n) = {}_{n-1}\mathrm{C}_{r-1} q^{r}(1-q)^{n-r}
$$
失敗回数を$x$として、以下のように置き換えることもできる。ある事象が$r$回生じるまでに、$x$回失敗する確率と言い換えることができる。この確率分布を負の二項分布という。

$$
P(x) = {}_{x+r-1}\mathrm{C}_{r-1} q^{r}(1-q)^{x}
$$

Rでも`nbinom`で負の二項分布の確率を計算することができる。

```{r}
x = 0:10
p_y = dnbinom(x = x, size = 3, prob = 0.5) #x = 失敗回数, size = 成功回数, prob = 成功確率

d_plot = data.frame(x = x, p_y = p_y)

ggplot2::ggplot() + 
  ggplot2::geom_bar(data = d_plot, aes(x = factor(x), y = p_y), stat = "identity") + 
  ggplot2::labs(x = "number of failures", y = "probability", title = "number of success = 3")

```


期待値$E(x)$と分散$Var(x)$は、以下から計算される。

$$
E(x) = \frac{r(1-q)}{q}\\
Var(x) = \frac{r(1-q)}{q^2}\\
$$

`dnbinom()`に期待値`mu`を入力しても、確率を計算してくれる。

```{r}

dnbinom(x = x, size = 3, prob = 0.5) 
dnbinom(x = x, size = 3, mu = 3*0.5/(1-0.5)) 

```


期待値を$E(x)=\mu$とすると、分散は$Var(x)=\mu + \mu^{2}/r$で、分散が期待値（平均）よりも$\mu^{2}/r$大きい。負の二項分布によって、分散が平均よりも大きい分布を扱うことができる。   
  
  
### Rでの負の二項回帰


Rでは、`MASS`パッケージに含まれている`glm.nb()`関数で、負の二項回帰を扱うことができる。Rに入っている`warpbreaks`をサンプルデータとして、ポアソン回帰と負の二項回帰の結果を比較してみよう。

```{r}

d = warpbreaks #別の名前(d)で保存する
d$A <- ifelse(d$wool == "A", 1, 0) #Aなら1, Bなら0のダミー
head(d)

ggplot2::ggplot() + 
  ggplot2::geom_histogram(data = d, aes(x = breaks, fill = wool), binwidth = 1)

```

`breaks`に対する`wool`(A or B)の効果を検討する。まずは、ポアソン回帰の結果を見てみる。`breaks`を$y$、`A`を$x$とすると、モデルは以下のように表現できる。

$$
\lambda = \alpha + \beta x\\
y \sim \text{Poisson}(\lambda)
$$


```{r}
model_poisson = glm(data = d, breaks ~ 1 + A, family = poisson(link = "log"))
summary(model_poisson)

mean(d$breaks)
var(d$breaks)

```

`A`に係る傾きの推定値について、かなり小さいp値が推定されている。  

```{r, include = FALSE}

library(performance)
performance::check_overdispersion(model_poisson)

```
  
次に、負の二項回帰の結果と比較してみよう。


$$
\mu = \alpha + \beta x\\
y \sim \text{NegativeBinom}(\mu, r)
$$


`MASS`パッケージの`glm.nb()`を使う。

```{r}

model_nb = MASS::glm.nb(data = d, breaks ~ 1 + A) #lm関数と同じ要領で、線形の式を入力する。確率分布はオプションで指定しないで良い。
summary(model_nb)

```

ポアソン回帰と比べると`A`のp値が大きくなり、過分散が解消されたことがうかがえる。


## 順序ロジスティック回帰

「優、良、可」といった成績や「1=当てはまらない、..., 5 = 当てはまる」といったリッカート尺度といった順序尺度はカテゴリカル変数であるので、正規分布に従う前提を置くなど量的変数のように扱うのは本来は適切ではない。二値のカテゴリカル変数の場合は二項分布を用いるロジスティック回帰で検討できたが、3つ以上のカテゴリを持つ変数の場合はどうすればよいか？  
  
応答変数が順序尺度である場合は、**順序ロジスティック回帰(ordred logistic regression)**が適切なモデルとされる。  


### 例題

例えば、`Score`を試験の成績を意味する順序尺度として「1=不可、2=可、3=良、4=優、5=秀」の値を取るとする。この成績`Score`に対して、試験前日の睡眠時間`Sleep`が及ぼす影響を検討するとしよう。  

```{r}

###サンプルデータの作成
Sleep = c(6,1,5,2,5,6,2,6,2,5,6,2,5,3,5,3,3,7,2,7,6,1,2,1,7,1,1,7,5,3)
Score = c(3,3,3,2,3,3,5,5,2,2,2,3,4,1,3,2,3,5,1,4,4,3,3,3,4,1,3,3,3,2)
sample_ordered = data.frame(Score = Score, Sleep = Sleep)
head(sample_ordered)

```

```{r}

ggplot2::ggplot() + 
  ggplot2::geom_jitter(data = sample_ordered, aes(x = Sleep, y = Score))

```

  
### 順序ロジスティック回帰モデルの詳細

#### 累積確率と累積ロジット{-}

順序のあるカテゴリカル変数を扱う場合には、**累積確率（cumulative probability）**で各変数が生じる確率を表現する。累積確率とは、順序変数のある値以下が生じる確率のことをいう。例えば、$y$が$k$以下の値を取る累積確率を$Pr(y≤k)$と表現する。 カテゴリ$k$が生じる確率$p_{k}$とすると、$p_{k}$は累積確率を用いて以下の式で表現することができる。

$$
p_{k}=Pr(y≤k)−Pr(y≤k−1)
$$

例えば試験の成績（1=不可、2=可、3=良、4=優、5=秀）を$y$として考えると、$Pr(y≤3)$は、試験の成績が1, 2もしくは3である確率を示している。試験の成績が3である確率$p_{3}$は、累積確率$Pr(y≤3)$から累積確率$Pr(y≤2)$を引くことで求めることができる。  
    
なお、カテゴリの最大値が出る確率は、全体の確率から引けば求まる。例えば、試験の成績が5である確率$p_{5}$は累積確率$Pr(y≤5)-Pr(y≤4)$を計算しなくとも、$1-Pr(y≤4)$で求めることができる。  



#### 線形予測子との関係 {-}

カテゴリ$k$が得られる累積確率$Pr(y ≤ k)$は、K-1個の切片$\alpha_{k}$で示すことができる（上で述べたように、最大カテゴリの確率は1から$Pr(y≤K-1)$を引けば求まるので、すべての確率を表現するために切片をK個用意する必要はない）。$\alpha_{k}$は累積確率を区切るポイントを意味し、*カットポイント(cutpoint)*とも呼ばれる。

$$
Pr(y≤k) = \frac{\exp(\alpha_{k})}{1+\exp(\alpha_{k})}
$$


更に、予測変数の効果（傾き）を考慮すると、累積確率は以下のように表現できる。

$$
\eta = \beta x\\
Pr(y ≤ k) = \frac{\exp(\alpha_{k} - \eta)}{1+\exp(\alpha_{k} - \eta)}
$$

以下のように書き換えることもできる（左辺を累積確率の対数オッズ、右辺を線形の式としたもの）。

$$
\eta = \beta x\\
\log\frac{Pr(y ≤ k)}{Pr(y > k)} = \alpha_{k} - \eta
$$

各切片から傾きの効果を引いているところに注意する必要がある。引くことによって、予測変数の値が大きいほど、累積確率の値が低くなる。言い換えれば、$Pr(y>k)$が大きくなる。つまり、傾きの効果を引くことによって、予測変数の値が大きくなるほど、より大きい値のカテゴリが生じる確率が大きくなることを表現できる。  
  
このように、順序ロジスティック回帰のモデルでは、各カテゴリの累積確率を決定づける切片$\alpha_{k}$と傾き$\beta$を用いて、各カテゴリが生じる確率を推定する。


### Rでの順序ロジスティック回帰

Rで順序ロジスティック回帰を行うには、外部パッケージの関数を利用する。以下では、`MASS`パッケージに含まれている`polr`関数を使って、先ほど作成したサンプルデータ`sample_ordered`で順序ロジスティック回帰を行う。
  

### 準備 {-}

解析の前に、Rで順序尺度を扱う場合は、変数を順序付きの因子型(factor)変数にする必要がある。`factor()`もしくは`ordered()`のいずれかの方法で作成する。

```{r}

#以下のいずれかの方法で因子型に変換する
sample_ordered$Score = factor(sample_ordered$Score, levels = c("1", "2", "3", "4", "5"), ordered = TRUE)
sample_ordered$Score = ordered(sample_ordered$Score, levels = c("1", "2", "3", "4", "5"))
#levelsで、水準の順序を指定する
#factor()では、オプションoredered=TRUEを加える

```

### 解析 {-}

応答変数を順序付きの因子型変数に変更したら、`ordinal`パッケージに含まれている`clm()`で解析する。`lm()`と同じ要領で、応答変数~予測変数のモデルを書けば結果を出力してくれる。

```{r, eval = TRUE, include=FALSE}

model_polr = MASS::polr(data = sample_ordered, Score ~ 1 + Sleep, Hess = TRUE)
summary(model_polr)

```

```{r}

model_ordinal = ordinal::clm(data = sample_ordered, Score ~ 1 + Sleep)
summary(model_ordinal)

```

### 解釈 {-}

`Coefficients`に予測変数に係る傾きの係数の推定値が出力されている。傾きの解釈は、一般化線形モデルのときと同じである（累積確率の対数オッズの変化量：要は係数がプラスならば、予測変数は高順位のカテゴリが生じる確率を上昇させる効果を持つと解釈すれば良い）。`Intercepts`に出力されているのは、順序ロジスティック回帰モデルの各切片（カットポイント）の推定値である。



```{r, include=FALSE, eval = FALSE}

#***
#`polr()`ではp値を出力してくれないので、求めたい場合は自分で計算する必要がある。t値を元に、以下のプログラムで計算する。

coef_table = coef(summary(model_polr))
p = pnorm(abs(coef_table[,"t value"]), lower.tail = FALSE)*2
(cbind(coef_table, "p value" = p))

#***

```



## 多項ロジスティック回帰

先ほどの成績（1=不可、2=可、3=良、4=優、5=秀）の例では、成績はカテゴリであるが順序関係のある順序尺度であった。順序関係がないカテゴリカル変数の場合はどうすればよいか？  
応答変数が3つ以上のカテゴリの名義尺度（順序関係がない）場合は、**多項ロジスティック回帰(multinomial logistic regression)**が適切である。

### 例題{-}

高校生が進学先（大学の学部）を選択する場合を例として考える。学部の種類（文学部、経済学部、理学部など）には順序関係はないので、学部の種類は名義尺度である。性別、高校のときの成績が学科選択に及ぼす影響を検討する。

```{r}
###サンプルデータの作成
set.seed(1)
Male = c(rep(0:1, 25))
Grade = rnorm(n=50, 5, 2)
Faculty = c(rep("Literature", 15), rep("Economics", 20), rep("Physical", 15))
sample_mnl = data.frame(Faculty = Faculty, Male = Male, Grade = Grade)
head(sample_mnl)

```

`Male`は性別（男=1, 女=0）、`Grade`は高校の時の成績、`Faculty`は志望学部を意味する変数とする。`Faculty`には、`Literature`（文学部）、`Economics`（経済学部）、`Physical`（理学部）の3種類のカテゴリがあるとする。

### 多項ロジスティック回帰モデルの詳細

多項ロジスティック回帰では基準となるカテゴリを設定し、基準カテゴリと比べて各カテゴリが生じやすいかを推定する複数のモデルを設定する。  
  
例えば、経済学部(Economics)を基準カテゴリとする。他のカテゴリ(Literature, Physical)が生じる確率を線形の式で表した例を以下に示す。

$$
\log\frac{Pr(Literature)}{Pr(Economics)}= \alpha_{1} + \beta_{1,1} Male + \beta_{2,1} Grade \\
\log\frac{Pr(Physical)}{Pr(Economics)}= \alpha_{2} + \beta_{1,2} Male + \beta_{2,2} Grade \\
$$

多項ロジスティック回帰では、カテゴリごとに異なる線形予測子を設定し、それぞれ異なる切片と傾きの値を推定する。

### Rでの多項ロジスティック回帰

Rには多項ロジスティック回帰を行うための関数として、`nnet`パッケージの`multinom()`関数がある。`lm()`と同じ要領でモデルを記述すると、推定結果を出力してくれる。先ほど作ったサンプルデータ`sample_mnl`で、多項ロジスティック回帰を行ってみる。

```{r, message=FALSE, warning=FALSE}

result_mnl = nnet::multinom(data = sample_mnl, Faculty ~ 1 + Male + Grade)
summary(result_mnl)

```



`Coeffficients`の部分に、係数の推定結果が出力される。このモデルでは`Economics`が基準カテゴリとなっている（デフォルトで、アルファベット順で一番はじめに出てくるカテゴリが基準となる）。`Literature`の部分に出力されるのが上の式でいう$\alpha_{1}$, $\beta_{1, 1}$, $\beta_{2, 1}$に、`Physical`の部分に出力されるのが$\alpha_{2}$, $\beta_{1, 2}$, $\beta_{2, 2}$に相当する。  
  
`Literature`の予測変数の傾きの推定値は、基準カテゴリ（`Economics`）と比べた上でのその予測変数の効果を意味する（その予測変数が1単位変化したときの`Literature`と`Economics`の対数オッズの変化量）。  
  
このように、多項ロジスティック回帰の係数はある基準カテゴリと比較した上での効果を意味するため、解釈は複雑になる。


*** 

`multinom()`ではp値を出力してくれないので、求めたい場合は自分で計算する必要がある。以下には、z scoreを元に計算する方法を示す。

```{r}

#p値の出力
z = summary(result_mnl)$coefficients/summary(result_mnl)$standard.errors
p = (1 - pnorm(abs(z), mean = 0, sd = 1)) * 2
p

```

***



```{r, include = FALSE}

## ゼロ過剰ポアソン回帰

#ゼロ過剰ポアソン回帰は、データにゼロが極端に多いカウントデータに適用されるモデルである。ゼロ過剰ポアソン回帰は、二項分布とポアソン分布を混合させた統計モデルである。

### 例題{-}

#夏休みの間に毎日、カブトムシを採りに森に出かけた。カブトムシが何匹か見つかる日もあれば、全く見つからない日もある。その日の天気や気温がカブトムシが見つかる確率に影響を及ぼしていたかを検討するとする。

#サンプルデータの作成



### ゼロ過剰ポアソンモデルの詳細

#ゼロ過剰ポアソンモデルでは、観測値でゼロが生じる過程として、2つの過程を想定する。
#1. 二項分布からゼロが生じる場合
#2. ポアソン分布からゼロが生じる場合

#雨の降っている日は


### Rでのゼロ過剰ポアソン回帰

#`pscl`パッケージの`zeroinfl()`関数で解析することができる。`lm()`と同じ要領でモデルを記述すると、推定結果を出力してくれる。

head(bioChemists)

ggplot2::ggplot() + 
  ggplot2::geom_histogram(data = bioChemists, aes(x=art), binwidth = 1, fill="white", color="black")
table(bioChemists$art)


model_zeroinfl = pscl::zeroinfl(data = bioChemists, art ~ fem + mar + kid5 + phd + ment)
#model_zeroinfl = pscl::zeroinfl(data = bioChemists, art ~ fem + mar | kid5)

summary(model_zeroinfl)

#二項分布のモデル（binomial with logit link）とポアソン分布のモデル（poisson with log link）の2種類のモデルの推定結果が出力される。


```


## 確認問題{-}

`MASS`パッケージに入っているサンプルデータ、`housing`を使って練習をする。

```{r}

d = housing #dという名前で保存する
d$ID = 1:nrow(d)

head(d)

```

(1)Freqを応答変数、Contを予測変数としたポアソン回帰と、(2)同じくFreqを応答変数、Contを予測変数とした負の二項回帰を行い、結果を比較せよ。

```{r, include=FALSE, eval=FALSE}

mean(d$Freq)
var(d$Freq)

ggplot() + 
  geom_histogram(data = d, aes(x = Freq), binwidth = 1)

model_poisson = glm(data = d, Freq ~ 1 + Cont, family = poisson(link = "log"))
summary(model_poisson)
performance::check_overdispersion(model_poisson)

model_nb = MASS::glm.nb(data = d, Freq ~ 1 + Cont)
summary(model_nb)

```
