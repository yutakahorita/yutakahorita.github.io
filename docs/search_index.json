[
["06-NHT.html", "Chapter 7 統計的仮説検定 7.1 準備 7.2 統計的仮説検定の考え方 7.3 統計的仮説検定の種類 7.4 統計的仮説検定で重要な概念 7.5 統計的検定が抱える問題 確認問題", " Chapter 7 統計的仮説検定 統計的仮説検定の考え方とそれが抱える問題について理解する。 統計的仮説検定の考え方（p値とは何か？） 第1種の過誤と第2種の過誤 p値とサンプル数との関係 7.1 準備 この章でも，tidyverseパッケージを使う。予めロードしておく。 library(tidyverse) 7.2 統計的仮説検定の考え方 前の章で学んだ二項分布を用いて，統計的仮説検定の考え方について学ぶ。p値とは何なのかを理解する。 7.2.1 二項分布の復習 コインを10回投げて表が出た回数\\(x\\)をカウントしていく。”理論的”には，表が\\(x\\)回出る確率\\(P(x)\\)は，コインを投げる回数\\(n\\)と表が出る確率\\(q\\)をパラメータとする二項分布に従う。 \\[ P(x) = {}_n\\mathrm{C}_xq^{x}(1-q)^{(n-x)}\\\\ x \\sim Binomial(n, q) \\] plot = data.frame(x=0:10, p=dbinom(x=0:10, size=10, prob=0.5)) ggplot() + geom_bar(data=plot, aes(x=factor(x), y=p), stat=&quot;identity&quot;) + labs(y = &quot;P(x)&quot;, x =&quot;x&quot;) 7.2.2 統計的仮説検定 ”理論的には”，表が出る回数\\(x\\)が生じる確率は上の図のようになる（平均は\\(nq = 10*0.5 = 5\\)）。 では，実際にコインを10回投げてみて表が出た回数を数えてみたところ，表が2回しか出なかったとする。この結果から，「このコインには歪みがあって，片一方の面だけが出やすい」と言ってもよいのか？ これを検討するために，表と裏それぞれが出る確率の等しいコインを投げる場合（すなわち，\\(q=0.5\\)の場合）との比較を行い，今回の実験結果がどれくらいまれな事象と言えるのかを比較する。 このとき，研究者が検証したい仮説を対立仮説（alternative hypothesis），対立仮説を検証するために比較の対象とする「偏りを仮定しない」仮説のことを帰無仮説(null hypothesis)と呼ぶ。 では，今回の帰無仮説となる二項分布（2つのパラメータが，\\(n=10, q=0.5\\)の場合)の分布を見てみよう。理論的には，表が\\(x\\)回出る確率\\(P(x)\\)は，\\(x\\)それぞれについて以下のようになる。 d = data.frame(x=0:10, p_x =dbinom(x=0:10, size=10, prob=0.5)) d ## x p_x ## 1 0 0.0009765625 ## 2 1 0.0097656250 ## 3 2 0.0439453125 ## 4 3 0.1171875000 ## 5 4 0.2050781250 ## 6 5 0.2460937500 ## 7 6 0.2050781250 ## 8 7 0.1171875000 ## 9 8 0.0439453125 ## 10 9 0.0097656250 ## 11 10 0.0009765625 表もしくは裏が出る回数が2回以下の場合の確率を計算すると， d$p_x[1] + d$p_x[2] + d$p_x[3] + d$p_x[9] + d$p_x[10] + d$p_x[11] ## [1] 0.109375 となる。つまり，もし歪みのないコインならば，片一方の面だけが出る回数が2回以下の確率はおおよそ0.11ということになる。 この例で求めた確率0.11のように，「帰無仮説の前提のもとで，特定の実験結果が得られる確率」をp値と呼ぶ。 p = 0.11 は小さい確率のように思える。なので，「歪みのないコインならば，一方の面が2回出る確率は本来0.11である。本来だったらあまり起こり得ない実験結果が得られたので，このコインは歪みのないコインであると結論づけるのは自然ではない。ゆえに，このコインには歪みがあって片一方の面が出やすい」という結論を出すのが妥当なように思える。 しかし，人によって0.11を小さいと評価しても良いのか，基準が分かれる。そこで，研究者の間でどこまでの数値を小さいと評価するかの基準が決まっている。この基準となる確率が，有意水準である。 一般的に有意水準には0.05（5%）とされることが多い。ただし，なぜ5％を判断基準とするのかについては特に明確な理由はない（みんなから合意されているからという以上の理由はない）。 つまり，「帰無仮説（フェアなコインを投げる）の前提のもとでは，表が出る回数が2回以下の確率は0.11 であった。これは小さい確率のように思えるが，判断基準の5％よりかは大きい。すなわち，このコインはゆがんでいると結論付ける訳にはいかない」ことになる。 以上が，統計的仮説検定の考え方である。まとめると， 1)ある特定の理論分布（帰無仮説）のもとで今回の実験結果が生じる確率（p値）を求め， 2)その確率が小さいかを評価し， 3)小さい場合は帰無仮説を棄却する というのが，統計的仮説検定のプロセスである。 今回のように「コインが表か裏かに関わらず，一方の面だけが出やすい」という対立仮説を検討する場合の検定は，両側検定という。仮に，今回の仮説で表と裏を区別するとして「表が出にくい」つまり「表が出る回数が2回以下の確率」を対象とする場合，このような検定を片側検定という。二項分布は左右対称の分布なので，両側p値は片側p値の2倍の値である(厳密には左右対称ではないのであくまで近似値)。多くの場合，両側検定を使うのが一般的である。 7.3 統計的仮説検定の種類 7.3.1 二項検定 コイン投げの例は，二項分布に従う事象である。二項分布に従う事象の統計的仮説検定は，二項検定と呼ばれる。 Rにも，二項検定を行うための関数binom.test()が用意されている。 binom.test()に二項分布のパラメータ（\\(n\\)と\\(q\\)にあたる数値）と実験結果を入れると，p値を求めてくれる。 上の例について，binom.test()でp値を求めてみよう。 binom.test(x = 2, n = 10, p = 0.5) #出てくる結果はデフォルトで両側検定になる。 ## ## Exact binomial test ## ## data: 2 and 10 ## number of successes = 2, number of trials = 10, p-value = 0.1094 ## alternative hypothesis: true probability of success is not equal to 0.5 ## 95 percent confidence interval: ## 0.02521073 0.55609546 ## sample estimates: ## probability of success ## 0.2 7.3.2 t検定 心理統計では，2つのグループの間で平均値に差があるかどうかの統計的仮説検定として，t検定を使うことが多い。連続量の変数を扱う検定の場合は，t検定がよく使われる。 t検定の考え方も，基本的に上と同じである。2つの集団の間で平均値に差がないと仮定したときの理論分布（t分布）と比べて，実際に得られた値がどれくらい珍しいのかを検討する。 Rにも，t検定を行うための関数t.test()が標準で入っている。 まず，以下のプログラムを実行して，サンプルデータを作る。 set.seed(1) Value = c(rnorm(n = 10, mean = 0, sd = 1), rnorm(n = 10, mean = 1, sd = 1)) Treatment = c(rep(&quot;X&quot;, 10), rep(&quot;Y&quot;, 10)) sample_data = data.frame(Treatment = Treatment, Value = Value) str(sample_data) ## &#39;data.frame&#39;: 20 obs. of 2 variables: ## $ Treatment: chr &quot;X&quot; &quot;X&quot; &quot;X&quot; &quot;X&quot; ... ## $ Value : num -0.626 0.184 -0.836 1.595 0.33 ... 実験でXとYの２つの条件(Treatment)を設定し，ある値（Value）を測定したとする。 まず，2つの条件別にValueの平均値や標準偏差を求める。 sample_data %&gt;% group_by(Treatment) %&gt;% summarise(Mean = mean(Value), SD = sd(Value), N = length(Value)) ## # A tibble: 2 x 4 ## Treatment Mean SD N ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 X 0.132 0.781 10 ## 2 Y 1.25 1.07 10 条件Yの方が条件Xよりも平均値が大きいよう見えるが，そう結論づけて良いのか。これをt検定で検討しよう。 まず，2つの集団間の平均値の差を元に，以下の式から「t値」を求める。 \\[ t = \\frac{\\bar{X} - \\bar{Y}}{\\sqrt{\\sigma^2_{X}/n_{X}+\\sigma^2_{Y}/n_{Y}))}} \\] \\(\\bar{X}\\)と\\(\\bar{Y}\\)はそれぞれ条件Xと条件Yの平均値，\\(\\sigma^2_{X}\\)と\\(\\sigma^2_{Y}\\)はそれぞれ条件Xと条件Yの分散，\\(n_{X}\\)と\\(n_{Y}\\)はそれぞれ条件Xと条件Yのサンプル数である。 XとYが同じ正規分布\\(Normal(\\mu, \\sigma^2)\\)から抽出される場合，t値は自由度\\(n_{X}+n_{Y}-2\\)のt分布に従う。 つまり，同じ平均値を持つ母集団からXとYが抽出された（つまり，\\(\\bar{X} = \\bar{Y}\\)のとき）と仮定した上でp値を求め，今回のデータが得られる確率がどのくらいまれであるかを検討する。 Rのt.test()関数を使って実験データの情報を入力すれば，p値を求めてくれる。 t.test(data = sample_data, Value ~ Treatment) #dataにデータの名前，比較の対象となる変数~グループを意味する変数とうかたちで入力すると結果が出力される。 ## ## Welch Two Sample t-test ## ## data: Value by Treatment ## t = -2.6669, df = 16.469, p-value = 0.01658 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -2.0022169 -0.2310675 ## sample estimates: ## mean in group X mean in group Y ## 0.1322028 1.2488450 p値は0.02であった。これは5%よりも小さいので，「今回の結果が生じる確率はまれである。XとYの母集団の平均値は等しいちう帰無仮説を棄却し，XとYは平均値が異なる集団を母集団とする」と結論づけることになる。 t検定には，2つの標本の母集団の分散が等しいと仮定するかしないかで二種類の検定がある。母集団の分散が等しいと仮定しない場合の検定はウェルチの検定(Welch’s t-test)と呼ばれ，Rのt.test()関数でデフォルトで出る検定結果はこのウェルチの検定による結果である。一般的に2つの標本の母分散は不明であるので，それらが等しいかどうかも不明である。なので，等分散を仮定しないt検定をしておくほうが保守的である。 7.4 統計的仮説検定で重要な概念 7.4.1 第1種の過誤と第2種の過誤 「帰無仮説が真なのに，帰無仮説を棄却してしまう誤り」のことを，第1種の過誤（type Ⅰ error）という。つまり，「本当は差がないのに，”差がある”と判断してしまう誤り」のことである。 これに対し，「帰無仮説が偽なのに，帰無仮説を採択してしまう」誤りのことを，第2種の過誤（type Ⅱ error）という。つまり，「本当は差があるのに，”差がない”と判断してしまう誤り」のことである。 第1種の過誤を犯す確率\\(\\alpha\\)は，要は有意水準の値そのものである（\\(\\alpha=0.05\\)）。有意水準を高くする，すなわち「差があると判断する上での基準をゆるく」してしまうと，誤った仮説を採用してしまう恐れが増えてしまう。 第2種の過誤を犯す確率を\\(\\beta\\)と表現する。\\(1 - \\beta\\)は検定力と呼ばれ，検定力とは「帰無仮説が偽であるときに，正しく帰無仮説を棄却する確率」のことをいう。つまり，差があるときに，”差がある”と正しく判断できる確率のことである。統計的仮説検定では，この検定力をいかに高く保つかが重要となる。 第1種の過誤と第2種の過誤はトレード・オフの関係にある。第1種の過誤を避けようとして有意水準を小さくすれば（例えば\\(\\alpha=0.001\\)とする）帰無仮説の棄却が厳しくなり，逆に第2種のエラーを犯してしまう確率も高くなる（帰無仮説が偽であるにもかかわらず，棄却しない）。 7.5 統計的検定が抱える問題 7.5.1 p値と標本数の関係 p値は標本数に依存する。標本数が多くなるほどp値は小さくなる。 再び，コイン投げの例に戻る。先程の例では，コインを10回投げて2回表が出たケースについて二項検定で評価をしたが，今度は100回コインを投げて20回表が出た場合についても二項検定をしてみよう。 どちらのケースも，表が出る割合は0.2で等しい。 binom.test()関数で，「フェアなコインの場合と比べてこのコインはゆがんでいるか」を検討してみよう。 binom.test(x = 2, n = 10, p = 0.5) #表が出る確率0.5のコインを10回(n=10)なげて，2回(x=2)表が出た ## ## Exact binomial test ## ## data: 2 and 10 ## number of successes = 2, number of trials = 10, p-value = 0.1094 ## alternative hypothesis: true probability of success is not equal to 0.5 ## 95 percent confidence interval: ## 0.02521073 0.55609546 ## sample estimates: ## probability of success ## 0.2 binom.test(x = 20, n = 100, p = 0.5)#表が出る確率0.5のコインを100回(n=100)なげて，20回(x=20)表が出た ## ## Exact binomial test ## ## data: 20 and 100 ## number of successes = 20, number of trials = 100, p-value = 1.116e-09 ## alternative hypothesis: true probability of success is not equal to 0.5 ## 95 percent confidence interval: ## 0.1266556 0.2918427 ## sample estimates: ## probability of success ## 0.2 100回コインを投げたケースについては，p値が1.115908910^{-9}と非常に小さい値となった。 二項分布\\(Binomial(n = 100, q = 0.5)\\)のグラフも確認してみよう。\\(x &lt; 20\\)が非常に小さい確率であることがグラフからもわかる。 plot = data.frame(x=0:100, p=dbinom(x=0:100, size=100, prob=0.5)) ggplot() + geom_bar(data=plot, aes(x=factor(x), y=p), stat=&quot;identity&quot;) + scale_x_discrete(breaks = seq(0,100,10)) + labs(y = &quot;P(x)&quot;, x =&quot;x&quot;) 「有意ではない（\\(p &gt; 0.05\\)）」というのは，「差がない」ということを意味しない。差自体は常に存在する（今回の実験結果0.2とフェアなコインの結果0.5の間には，0.3という差が存在する）。統計的仮説検定で評価するのは，その差が意味のある差かどうかである。 少ない標本数では，珍しい結果が生じることもありえる。10回投げた程度では，その差が意味のある差かどうかが，標本数が少なすぎて判断できない。 逆に，実質意味のない差であっても，標本数が多ければ統計的に有意な差（\\(p &lt; .05\\)）が得られてしまう。もっと極端に，10,000回コインを投げて，表が出た回数が4,900回だった場合（つまり表が出る割合は0.49）を考えてみよう。このコインがフェアなコインよりも歪んでいるかを検定してみると，有意（\\(p &lt; .05\\)）な結果が得られる。 n = 10000 x = 0.49 * n binom.test(x = x, n = n, p = 0.5) ## ## Exact binomial test ## ## data: x and n ## number of successes = 4900, number of trials = 10000, p-value = 0.04659 ## alternative hypothesis: true probability of success is not equal to 0.5 ## 95 percent confidence interval: ## 0.4801563 0.4998496 ## sample estimates: ## probability of success ## 0.49 しかし，0.49と0.50の差，すなわち1%の違いを意味のある差と判断してよいのだろうか？ このように，統計的仮説検定には差の有無の評価が標本数に依存する欠点がある。実質意味のない大きさの差でも，場合によっては「有意な差がある」と結論付けられてしまうときもある。 統計的仮説検定で検討しているのは，差の大きさ（効果の大きさ）ではないということには注意が必要である。 7.5.2 多重比較の問題 統計的仮説検定を繰り返すほど，差がなくても差があると評価してしまう確率（つまり第1種の過誤を犯す確率）は増える。 例えば，5%水準で10回検定を行えば，少なくとも1回は帰無仮説を誤って棄却してしまう確率が0.4 になる。 1 - (1 - 0.05)^10 #全ての確率から，「10回検定を行って全て正しい判断を行う」確率を差し引いたものが，「少なくとも1回は誤った判断をしてしまう確率」 ## [1] 0.4012631 このように複数回検定を行うことを多重比較という。 これにより，例えば心理学の研究ならば以下のように「有意な結果」を恣意的に導くことも可能である。 たくさんの質問項目について個別に検定を行い，有意な結果だけを選んで議論する。 たくさん実験を行って，有意な結果だけを選んで報告する。 このように，「有意な結果」を導くトリックはp-haking（ピー・ハッキング）と表現されることがある。 確認問題 問１ 以下のプログラムを読み込む。 ある教授法に児童の学力向上の効果があるかを検討した。学校Bにはその教授法を実施し，学校Aには何もしなかった。その後，学校Aと学校Bそれぞれ10人の生徒に学力テストを行った。A，Bそれぞれが学校A，Bそれぞれの生徒の成績である（架空のデータである）。 A = c(38, 53, 61, 27, 54, 55, 44, 45, 44, 41) B = c(48, 40, 43, 56, 69, 53, 47, 41, 42, 91) Value = c(A, B) Treatment = c(rep(&quot;A&quot;, 10), rep(&quot;B&quot;, 10)) sample = data.frame(Treatment = Treatment, Value = Value) str(sample) ## &#39;data.frame&#39;: 20 obs. of 2 variables: ## $ Treatment: chr &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;A&quot; ... ## $ Value : num 38 53 61 27 54 55 44 45 44 41 ... 学校Aと学校Bそれぞれについて，テストの得点の平均値及び標準偏差を求めて報告せよ。 この教授法に成績向上があったかどうかについてt検定（等分散を仮定しない）で検討し，結果について報告するとともに結論を述べよ。 ※t.test()関数を使う。等分散を仮定しない検定の場合は，特にオプションをしていしないでもよい。 "]
]
